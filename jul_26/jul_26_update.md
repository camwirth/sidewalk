# July 26 Meeting with Dr. Qi

## Notes from the paper _Co-mining: Self-Supervised Learning for Sparsely Annoatated Object Detection_


### Generate Pseudo labels

The paper states:

> Inspired by the practice in semi-supervised object detection, one straightforward solution for SAOD (Sparsely Annotated Object Detection) is to <u>first train a detector with sparse annotations and then use the pseudo labels generated by the learned model to retrain a new detector.</u> However, since the first learned model is deeply confused by the unlabeled instances, the generated pseudo labels for the second detecor learning are still of low credibility.

I ran training to investigate whether utilizing pseudo labels generated by the learned model would lead to improved performance with our dataset. 

1. Data Preparation
    - using a pre-trained model on original train dataset, predictions were generated for the entire train dataset
    - To ensure higher confidence in the predictions, predictions with a confidence threshold lower than 0.7 were filtered out
    - To prevent multiple labels for a single object, only one label sfrom multiple predictiosn with an IoU greater than 0.5 was selected 
2. Run Training
    - Two models were trained: one on the original train dataset and another on the dataset improved with pseudo labels generated in the previous step

**Results**

The performance of both models on the original test set and an improved test set were evaluated.

Results from Original Test Set

| Model                        | Precision | Recall | mAP@0.5 |
|------------------------------|-----------|--------|---------|
| Original Train Set           |
| Train set with pseudo labels |

Results from Improved Test Set

| Model                        | Precision | Recall | mAP@0.5 |
|------------------------------|-----------|--------|---------|
| Original Train Set           |
| Train set with pseudo labels |

The results demonstrate that employing pseudo labels for SAOD can lead to significant improvements in both precision and recall when compared to using the original train dataset alone. This suggests that the approach of leveraging pseudo labels generated from a pre-trained model can be an effective strategy for SAOD tasks.

However, we observed that despite the overall improvements, the precision of the model trained on the dataset with pseudo labels remains around 50%. This could be attributed to the low credibility of the pseudo labels themselves. Since the initial model is deeply confused by unlabeled instances, the generated pseudo labels may not be entirely reliable, leading to imprecise predictions.

### Co-mining

I found some especially interesting parts of co-mining that I think could be beneficial for our dataset. 